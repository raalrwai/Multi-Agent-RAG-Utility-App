{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff95c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import zipfile\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e619e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8785f50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048d91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "zip_file_path = 'Electricity_bills.zip'\n",
    "data_dir = os.path.join(cur_dir,'data\\\\')\n",
    "pdf_dir = os.path.join(data_dir, 'pdf\\\\')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "if not os.path.exists(pdf_dir):\n",
    "    os.mkdir(pdf_dir)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "    zip_file.extractall(pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e180b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpeg_dir = os.path.join(data_dir, 'jpeg\\\\')\n",
    "if not os.path.exists(jpeg_dir):\n",
    "    os.mkdir(jpeg_dir)\n",
    "\n",
    "\n",
    "for pdf in os.listdir(pdf_dir):\n",
    "    image = convert_from_path(os.path.join(pdf_dir,pdf))\n",
    "    image[0].save(os.path.join(jpeg_dir,pdf[:-4]+'.jpeg'), 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbdac833",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fb896da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_embed_file(file_name, multi_modal_model='gpt-4.1-mini', embedding_model='text-embedding-3-small'):\n",
    "  def create_file(file_path):\n",
    "    with open(file_path, \"rb\") as file_content:\n",
    "      result = client.files.create(\n",
    "          file=file_content,\n",
    "          purpose=\"vision\",\n",
    "      )\n",
    "      return result.id\n",
    "\n",
    "  file_id = create_file(file_name)\n",
    "\n",
    "  response = client.responses.create(\n",
    "      model = multi_modal_model,\n",
    "      input=[{\n",
    "            'role':'user',\n",
    "            'content':[{\n",
    "                'type': 'input_text',\n",
    "                    'text': 'what\\'s in this image?'},\n",
    "                {'type':'input_image',\n",
    "                    'file_id':file_id}\n",
    "            ]\n",
    "      }]\n",
    "  )\n",
    "  caption = response.output_text\n",
    "  embedding_object = client.embeddings.create(input=caption, model=embedding_model)\n",
    "  vector = embedding_object.data[0].embedding\n",
    "\n",
    "  # Display Results\n",
    "  # Display Image from URL\n",
    "  # os.system('wget %s' %image_url_)\n",
    "  # file_name=str(image_url_).split(\"/\")[-1]\n",
    "#   print(file_name)\n",
    "#   img = cv2.imread(file_name)\n",
    "#   cv2_imshow(img)\n",
    "#   print(caption)\n",
    "#   print(\"Summary Length in characters:\"+str(len(caption)))\n",
    "\n",
    "\n",
    "  return_dict = {'image_caption': caption, 'file_id':file_id, 'embedding':vector}\n",
    "\n",
    "  return return_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2e67035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id', 'values', 'metadata'])\n",
    "\n",
    "i=0\n",
    "for jpeg in os.listdir(jpeg_dir):\n",
    "    file_path = os.path.join(jpeg_dir, jpeg)\n",
    "    embedding = vision_embed_file(file_path)\n",
    "    df.loc[i] = [embedding['file_id'], embedding['embedding'], {'caption':embedding['image_caption']}]\n",
    "    i += 1\n",
    "\n",
    "df.to_csv(os.path.join(data_dir, 'embeds.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bb3fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 3}},\n",
       " 'total_vector_count': 3,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "index = pc.Index('retrieval-augmented-generation')\n",
    "index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43656a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_DF(df):\n",
    "  import json,ast\n",
    "  try: df=df.drop('Unnamed: 0',axis=1)\n",
    "  except: print('Unnamed Not Found')\n",
    "  df['values']=df['values'].apply(lambda x: np.array([float(i) for i in x.replace(\"[\",'').replace(\"]\",'').split(',')]))\n",
    "  df['metadata']=df['metadata'].apply(lambda x: ast.literal_eval(x))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79e7a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed Not Found\n"
     ]
    }
   ],
   "source": [
    "index_df = prepare_DF(pd.read_csv(os.path.join(data_dir,'embeds.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0fe143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_vectors = list(index_df.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bccc7e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 20}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(vectors=upsert_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f6743fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 23}},\n",
       " 'total_vector_count': 23,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27584e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549ef04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
